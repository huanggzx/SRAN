
<<<<<<< HEAD

###Towards Information Diversity Through Separable  Cascade Modules for Image Super Resolution.[[Paper]](http://#)[[Project]](https://huanggzx.github.io/SRAN/)

##### by  Zhenxing Huang, Jincai Chen*, Ping Lu, Dong Liang, Senior Member, IEEE, Hairong Zheng, Senior Member, IEEE, Zhanli Hu*, Senior Member, IEEE


----------
Note:
=======
# Deep Separable Residual Attention Network for Image Super Resolution
<br/>**[Zhenxing Huang](https://github.com/huanggzx/SRAN/), [Jincai Chen](https://github.com/huanggzx/SRAN/), [Ping Lu](https://github.com/huanggzx/SRAN/), [Zhanli Hu](https://github.com/huanggzx/SRAN/)**
<br/>**National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China**
<br/>**Key Laboratory of Information Storage System (School of Computer Science and Technology, Huazhong University of Science and Technology**
<br/>**Shenzhen Institutes of Advanced Technology,Chinese Academy of Sciences,Shenzhen,China**

![img](https://github.com/huanggzx/SRAN/blob/master/images/SRAN.png)

## Materials

[Paper](https://github.com/huanggzx/SRAN/) 

[Results(BaiduYun)](https://github.com/huanggzx/SRAN/)

## Abstract 

Convolution neural network (CNN) has been largely
applied to learn the mapping function between low resolution
(LR) images and high resolution (HR) ones, which has made
great progress in single image super resolution (SISR) domain.
With the aid of deeper networks through cascading collaborative
blocks, several works has improve image quality effectively.
In these works, the local cascading block are usually treated
as an atomic term to extend, which is a convenient way to
construct deep structures to extract feature and fuse information.
However, this would primarily limit the representation of the
latter reconstruction layer for its lack of abundant features if
the local atomic block could output only one type information.
For instance, the residual block could only contain residual
information.
>>>>>>> d6dac9a0d4880fb67aab0fa7e449e8ffa22ff65c

	We will give our train and test codes latter. 

<<<<<<< HEAD



=======
## Information Conduction Ways
![img](https://github.com/huanggzx/SRAN/blob/master/images/SB.png)

## Separable Residual Attetnion Blocks
![img](https://github.com/huanggzx/SRAN/blob/master/images/SRAB.png)

## Ablation Analysis
![img](https://github.com/huanggzx/SRAN/blob/master/images/Ablation.png)

## Visualization
![img](https://github.com/huanggzx/SRAN/blob/master/images/Visual.png)

## Results

![img](https://github.com/huanggzx/SRAN/blob/master/images/Results_1.png)
![img](https://github.com/huanggzx/SRAN/blob/master/images/Results_2.png)
![img](https://github.com/huanggzx/SRAN/blob/master/images/Results.png)

## Citation
<code>
@InProceedings{wang2019edvr,  
&emsp;&emsp;&emsp;&emsp;         author = {Wang, Xintao and Chan, Kelvin C.K. and Yu, Ke and Dong, Chao and Loy, Chen Change},  
&emsp;&emsp;&emsp;&emsp;          title = {EDVR: Video Restoration with Enhanced Deformable Convolutional Networks},  
&emsp;&emsp;&emsp;&emsp;          booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},  
&emsp;&emsp;&emsp;&emsp;          month = {June},  
&emsp;&emsp;&emsp;&emsp;          year = {2019}  
          }
</code>


## Concat 
If you have any question, please contact Zhenxing Huang at **huangzx@hust.edu.cn**.
>>>>>>> d6dac9a0d4880fb67aab0fa7e449e8ffa22ff65c
